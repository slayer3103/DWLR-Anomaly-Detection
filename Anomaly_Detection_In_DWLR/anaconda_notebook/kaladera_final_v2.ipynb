{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc98dfba-6891-4560-9bc6-b3efbc607543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Depth...\n",
      "Epoch 1/50\n",
      "730/730 [==============================] - 14s 16ms/step - loss: 0.1085 - val_loss: 0.0585\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0523 - val_loss: 0.0460\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 12s 16ms/step - loss: 0.0446 - val_loss: 0.0429\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0416 - val_loss: 0.0332\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0349 - val_loss: 0.0327\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0323 - val_loss: 0.0300\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0290 - val_loss: 0.0261\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0279 - val_loss: 0.0257\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0251 - val_loss: 0.0226\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0234 - val_loss: 0.0276\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0224 - val_loss: 0.0229\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0215 - val_loss: 0.0208\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0209 - val_loss: 0.0184\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 11s 16ms/step - loss: 0.0196 - val_loss: 0.0212\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 18/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 19/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0173 - val_loss: 0.0184\n",
      "Epoch 20/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0168 - val_loss: 0.0160\n",
      "Epoch 21/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0162 - val_loss: 0.0143\n",
      "Epoch 22/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 23/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 24/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 25/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 26/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 28/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 29/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 30/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 34/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0125 - val_loss: 0.0180\n",
      "Epoch 35/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 36/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 37/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\depth_model_kaladera.h5\n",
      "Training model for Temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "730/730 [==============================] - 14s 16ms/step - loss: 0.0814 - val_loss: 0.0379\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0326 - val_loss: 0.0324\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0301 - val_loss: 0.0318\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0291 - val_loss: 0.0443\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 11s 16ms/step - loss: 0.0288 - val_loss: 0.0343\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0280 - val_loss: 0.0305\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0271 - val_loss: 0.0287\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0261 - val_loss: 0.0282\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0243 - val_loss: 0.0289\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 11s 16ms/step - loss: 0.0219 - val_loss: 0.0235\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 11s 16ms/step - loss: 0.0210 - val_loss: 0.0233\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0190 - val_loss: 0.0259\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0185 - val_loss: 0.0218\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 21s 28ms/step - loss: 0.0180 - val_loss: 0.0190\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0176 - val_loss: 0.0210\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 18/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0176 - val_loss: 0.0191\n",
      "Epoch 19/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0163 - val_loss: 0.0198\n",
      "Epoch 20/50\n",
      "730/730 [==============================] - 21s 29ms/step - loss: 0.0165 - val_loss: 0.0213\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\temperature_model_kaladera.h5\n",
      "Training model for Battery Level...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "730/730 [==============================] - 41s 50ms/step - loss: 0.0437 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0186 - val_loss: 0.0158\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 37s 50ms/step - loss: 0.0158 - val_loss: 0.0203\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0061 - val_loss: 0.0152\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 36s 50ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\battery_model_kaladera.h5\n",
      "Scalers saved to C:/Users/saura/Downloads/trained_model_v2\\scalers_kaladera.pkl\n",
      "Training complete. Models and scalers are saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import detrend\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Load and Preprocess Data\n",
    "# ==============================\n",
    "def load_and_preprocess_data(file_path, target_column, sequence_length, scaler_type='StandardScaler', detrend_data=False):\n",
    "    # Load data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Detrend the data if required (e.g., for Battery Level)\n",
    "    if detrend_data:\n",
    "        data[target_column] = detrend(data[target_column])\n",
    "\n",
    "    # Normalize the target column\n",
    "    if scaler_type == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    data[target_column] = scaler.fit_transform(data[[target_column]])\n",
    "\n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[target_column].iloc[i:i + sequence_length].values\n",
    "        sequences.append(seq)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequences = np.expand_dims(sequences, axis=2)  # Add feature dimension\n",
    "    return sequences, scaler\n",
    "\n",
    "# ==============================\n",
    "# Step 2: Define LSTM Autoencoder\n",
    "# ==============================\n",
    "def create_lstm_autoencoder(sequence_length, input_dim, latent_dim=32):\n",
    "    # Encoder\n",
    "    input_layer = Input(shape=(sequence_length, input_dim))\n",
    "    encoded = LSTM(latent_dim, activation='relu', return_sequences=False)(input_layer)\n",
    "    encoded = Dense(latent_dim // 2, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = RepeatVector(sequence_length)(encoded)\n",
    "    decoded = LSTM(latent_dim, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_dim))(decoded)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mae')\n",
    "    return autoencoder\n",
    "\n",
    "# ==============================\n",
    "# Step 3: Train and Save Models\n",
    "# ==============================\n",
    "def train_and_save_model(sequences, model_path, sequence_length, input_dim, latent_dim=32, epochs=50, batch_size=32):\n",
    "    # Define LSTM Autoencoder\n",
    "    model = create_lstm_autoencoder(sequence_length, input_dim, latent_dim)\n",
    "\n",
    "    # Train model with early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(sequences, sequences, epochs=epochs, batch_size=batch_size, validation_split=0.2, shuffle=True, callbacks=[early_stopping])\n",
    "\n",
    "    # Save model\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    return model\n",
    "\n",
    "# ==============================\n",
    "# Step 4: Main Script\n",
    "# ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    file_path = \"C:/Users/saura/OneDrive/Desktop/data_streaming/data_generators/kaladera/dwlrdata_kaladera_(1).csv\"\n",
    "    sequence_length = 30         # Number of timesteps per sequence\n",
    "    epochs = 50                  # Training epochs\n",
    "    batch_size = 32              # Batch size\n",
    "    output_dir = \"C:/Users/saura/Downloads/trained_model_v2\"  # Directory to save models\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Depth\n",
    "    print(\"Training model for Depth...\")\n",
    "    depth_sequences, depth_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Depth\", sequence_length=sequence_length, scaler_type='StandardScaler'\n",
    "    )\n",
    "    train_and_save_model(depth_sequences, os.path.join(output_dir, \"depth_model_kaladera.h5\"), sequence_length, input_dim=1, latent_dim=32, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Temperature\n",
    "    print(\"Training model for Temperature...\")\n",
    "    temperature_sequences, temperature_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Temperature\", sequence_length=sequence_length, scaler_type='StandardScaler'\n",
    "    )\n",
    "    train_and_save_model(temperature_sequences, os.path.join(output_dir, \"temperature_model_kaladera.h5\"), sequence_length, input_dim=1, latent_dim=32, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Battery Level\n",
    "    print(\"Training model for Battery Level...\")\n",
    "    battery_sequences, battery_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Battery Level\", sequence_length=sequence_length, scaler_type='MinMaxScaler', detrend_data=True\n",
    "    )\n",
    "    train_and_save_model(battery_sequences, os.path.join(output_dir, \"battery_model_kaladera.h5\"), sequence_length, input_dim=1, latent_dim=64, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Save scalers for future use\n",
    "    scalers = {\n",
    "        \"Depth\": depth_scaler,\n",
    "        \"Temperature\": temperature_scaler,\n",
    "        \"Battery Level\": battery_scaler\n",
    "    }\n",
    "    scaler_path = os.path.join(output_dir, \"scalers_kaladera.pkl\")\n",
    "    with open(scaler_path, \"wb\") as f:\n",
    "        pickle.dump(scalers, f)\n",
    "    print(f\"Scalers saved to {scaler_path}\")\n",
    "\n",
    "    print(\"Training complete. Models and scalers are saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616fe33-ccc2-443b-b110-10188cc0f547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
