{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05298bf3-779c-49b0-a981-fe9a08121f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Depth...\n",
      "Epoch 1/50\n",
      "730/730 [==============================] - 14s 15ms/step - loss: 0.0995 - val_loss: 0.0521\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0431 - val_loss: 0.0400\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0381 - val_loss: 0.0391\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0329 - val_loss: 0.0344\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0294 - val_loss: 0.0283\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0262 - val_loss: 0.0343\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0239 - val_loss: 0.0220\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0231 - val_loss: 0.0198\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0160 - val_loss: 0.0157\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0162 - val_loss: 0.0154\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0159 - val_loss: 0.0200\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 18/50\n",
      "730/730 [==============================] - 11s 14ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 19/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 20/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 22/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "730/730 [==============================] - 10s 13ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\depth_model_guwahati.h5\n",
      "Training model for Temperature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "730/730 [==============================] - 14s 15ms/step - loss: 0.0847 - val_loss: 0.0410\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0348 - val_loss: 0.0378\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 11s 14ms/step - loss: 0.0330 - val_loss: 0.0393\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0315 - val_loss: 0.0336\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0317 - val_loss: 0.0314\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0285 - val_loss: 0.0306\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 11s 14ms/step - loss: 0.0281 - val_loss: 0.0292\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0262 - val_loss: 0.0267\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0257 - val_loss: 0.0252\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 11s 14ms/step - loss: 0.0242 - val_loss: 0.0235\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0227 - val_loss: 0.0214\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 12s 16ms/step - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 12s 17ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 18/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0182 - val_loss: 0.0282\n",
      "Epoch 19/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 21/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 22/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 23/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 24/50\n",
      "730/730 [==============================] - 13s 18ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 25/50\n",
      "730/730 [==============================] - 14s 18ms/step - loss: 0.0156 - val_loss: 0.0206\n",
      "Epoch 26/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 27/50\n",
      "730/730 [==============================] - 12s 17ms/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 28/50\n",
      "730/730 [==============================] - 12s 16ms/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 29/50\n",
      "730/730 [==============================] - 12s 16ms/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 30/50\n",
      "730/730 [==============================] - 11s 16ms/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 31/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 32/50\n",
      "730/730 [==============================] - 11s 15ms/step - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 37/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0131 - val_loss: 0.0260\n",
      "Epoch 38/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 41/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "730/730 [==============================] - 10s 14ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\temperature_model_guwahati.h5\n",
      "Training model for Battery Level...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "730/730 [==============================] - 18s 20ms/step - loss: 0.0383 - val_loss: 0.0180\n",
      "Epoch 2/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0129 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0081 - val_loss: 0.0121\n",
      "Epoch 5/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 7/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 8/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 9/50\n",
      "730/730 [==============================] - 14s 19ms/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "730/730 [==============================] - 15s 20ms/step - loss: 0.0060 - val_loss: 0.0134\n",
      "Epoch 11/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 12/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 15/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 16/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 20/50\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "730/730 [==============================] - 15s 20ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Model saved to C:/Users/saura/Downloads/trained_model_v2\\battery_model_guwahati.h5\n",
      "Scalers saved to C:/Users/saura/Downloads/trained_model_v2\\scalers_guwahati.pkl\n",
      "Training complete. Models and scalers are saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\anomaly_detection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import detrend\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Load and Preprocess Data\n",
    "# ==============================\n",
    "def load_and_preprocess_data(file_path, target_column, sequence_length, scaler_type='StandardScaler', detrend_data=False):\n",
    "    # Load data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Detrend the data if required (e.g., for Battery Level)\n",
    "    if detrend_data:\n",
    "        data[target_column] = detrend(data[target_column])\n",
    "\n",
    "    # Normalize the target column\n",
    "    if scaler_type == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    data[target_column] = scaler.fit_transform(data[[target_column]])\n",
    "\n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[target_column].iloc[i:i + sequence_length].values\n",
    "        sequences.append(seq)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequences = np.expand_dims(sequences, axis=2)  # Add feature dimension\n",
    "    return sequences, scaler\n",
    "\n",
    "# ==============================\n",
    "# Step 2: Define LSTM Autoencoder\n",
    "# ==============================\n",
    "def create_lstm_autoencoder(sequence_length, input_dim, latent_dim=32):\n",
    "    # Encoder\n",
    "    input_layer = Input(shape=(sequence_length, input_dim))\n",
    "    encoded = LSTM(latent_dim, activation='relu', return_sequences=False)(input_layer)\n",
    "    encoded = Dense(latent_dim // 2, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = RepeatVector(sequence_length)(encoded)\n",
    "    decoded = LSTM(latent_dim, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_dim))(decoded)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mae')\n",
    "    return autoencoder\n",
    "\n",
    "# ==============================\n",
    "# Step 3: Train and Save Models\n",
    "# ==============================\n",
    "def train_and_save_model(sequences, model_path, sequence_length, input_dim, latent_dim=32, epochs=50, batch_size=32):\n",
    "    # Define LSTM Autoencoder\n",
    "    model = create_lstm_autoencoder(sequence_length, input_dim, latent_dim)\n",
    "\n",
    "    # Train model with early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(sequences, sequences, epochs=epochs, batch_size=batch_size, validation_split=0.2, shuffle=True, callbacks=[early_stopping])\n",
    "\n",
    "    # Save model\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    return model\n",
    "\n",
    "# ==============================\n",
    "# Step 4: Main Script\n",
    "# ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    file_path = \"C:/Users/saura/OneDrive/Desktop/data_streaming/data_generators/guwahati/dwlrdata_guwahati_final(1).csv\"\n",
    "    sequence_length = 30         # Number of timesteps per sequence\n",
    "    epochs = 50                  # Training epochs\n",
    "    batch_size = 32              # Batch size\n",
    "    output_dir = \"C:/Users/saura/Downloads/trained_model_v2\"  # Directory to save models\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Depth\n",
    "    print(\"Training model for Depth...\")\n",
    "    depth_sequences, depth_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Depth\", sequence_length=sequence_length, scaler_type='StandardScaler'\n",
    "    )\n",
    "    train_and_save_model(depth_sequences, os.path.join(output_dir, \"depth_model_guwahati.h5\"), sequence_length, input_dim=1, latent_dim=32, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Temperature\n",
    "    print(\"Training model for Temperature...\")\n",
    "    temperature_sequences, temperature_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Temperature\", sequence_length=sequence_length, scaler_type='StandardScaler'\n",
    "    )\n",
    "    train_and_save_model(temperature_sequences, os.path.join(output_dir, \"temperature_model_guwahati.h5\"), sequence_length, input_dim=1, latent_dim=32, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Battery Level\n",
    "    print(\"Training model for Battery Level...\")\n",
    "    battery_sequences, battery_scaler = load_and_preprocess_data(\n",
    "        file_path, target_column=\"Battery Level\", sequence_length=sequence_length, scaler_type='MinMaxScaler', detrend_data=True\n",
    "    )\n",
    "    train_and_save_model(battery_sequences, os.path.join(output_dir, \"battery_model_guwahati.h5\"), sequence_length, input_dim=1, latent_dim=64, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Save scalers for future use\n",
    "    scalers = {\n",
    "        \"Depth\": depth_scaler,\n",
    "        \"Temperature\": temperature_scaler,\n",
    "        \"Battery Level\": battery_scaler\n",
    "    }\n",
    "    scaler_path = os.path.join(output_dir, \"scalers_guwahati.pkl\")\n",
    "    with open(scaler_path, \"wb\") as f:\n",
    "        pickle.dump(scalers, f)\n",
    "    print(f\"Scalers saved to {scaler_path}\")\n",
    "\n",
    "    print(\"Training complete. Models and scalers are saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465c81e-c748-4299-b0d4-86accffc3b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
